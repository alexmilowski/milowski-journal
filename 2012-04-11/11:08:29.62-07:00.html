<article xmlns="http://www.w3.org/1999/xhtml" vocab="http://schema.org/" typeof="BlogPosting" resource="http://www.milowski.com/journal/entry/2012-04-11T11:08:29.620000-07:00">
<script type="application/ld+json">
{
"@context" : "http://schema.org/",
"@id" : "http://www.milowski.com/journal/entry/2012-04-11T11:08:29.620000-07:00",
"@type" : "BlogPosting",
"genre" : "blog",
"headline" : "Experiments with Big Weather Data in MarkLogic - The Naive Approach",
"description" : "I've heard over-and-over that [MarkLogic](http://www.marklogic.com/) is a fantastic XML database--you just import your documents and query away! ¬†Given the quality of the people that I personally know at MarkLogic, I'm sure that's true. ¬†Still, I wanted to put that to the test. ¬†Every database system has techniques for getting reasonable or  ‚Äúblindingly fast‚Äù performance and I wanted to see how that works and at what cost.",
"datePublished" : "2012-04-11T11:08:29.620000-07:00",
"dateModified" : "2012-04-11T11:08:29.620000-07:00",
"keywords" : "MarkLogic,big data,weather" ,
"author" : [ { "@type" : "Person", "name" : "Alex Mi≈Çowski" }]
}
</script>
<section class="info">

<div class="metadata">
<p>
<a href="http://www.milowski.com/journal/entry/2012-04-11T11:08:29.620000-07:00" title="link to this entry">üîó</a> Published on
<span property="datePublished" content="2012-04-11T11:08:29.620000-07:00">2012-04-11 11:08:29.620000-07:00</span>
<span property="dateModified" content="2012-04-11T11:08:29.620000-07:00"></span>
</p>
<p property="keywords">MarkLogic,big data,weather</p>
<p property="description">I've heard over-and-over that [MarkLogic](http://www.marklogic.com/) is a fantastic XML database--you just import your documents and query away! ¬†Given the quality of the people that I personally know at MarkLogic, I'm sure that's true. ¬†Still, I wanted to put that to the test. ¬†Every database system has techniques for getting reasonable or  ‚Äúblindingly fast‚Äù performance and I wanted to see how that works and at what cost.</p>
</div>
</p>
<p property="author" typeof="Person"><span property="name">Alex Mi≈Çowski</span></p>
</section>
<h1>Experiments with Big Weather Data in MarkLogic - The Naive Approach</h1>
<p>I've heard over-and-over that <a href="http://www.marklogic.com/">MarkLogic</a> is a fantastic XML database--you just import your documents and query away! ¬†Given the quality of the people that I personally know at MarkLogic, I'm sure that's true. ¬†Still, I wanted to put that to the test. ¬†Every database system has techniques for getting reasonable or  ‚Äúblindingly fast‚Äù performance and I wanted to see how that works and at what cost.</p>
<p>The process that receives the APRS weather reports from the <a href="http://www.wxqa.com/">CWOP</a> produces data in five minute segments stored in separate documents and from each of the three APRS-IS servers. ¬†Each document produced is between 130K and 430K in size and contains between 450 to 1600 weather reports. ¬†Each hour, 36 of those documents are produced. ¬†On average, about 17MB per hour, or 12GB per month, of data is produced.</p>
<p>The documents produced have the following structure:</p>
<pre><code>&lt;aprs xmlns=&quot;http://weather.milowski.com/V/APRS/&quot; source=&quot;cwop.tssg.org&quot; start=&quot;2012-04-11T16:03:29Z&quot;&gt;
&lt;report from=&quot;CW1367&quot; type=&quot;weather&quot; latitude=&quot;40.7&quot; longitude=&quot;-74.2&quot;¬†
received=&quot;2012-04-11T16:03:29Z&quot; at=&quot;2012-04-13T17:12:00Z&quot;
wind-dir=&quot;340&quot; wind-speed=&quot;9&quot; wind-gust=&quot;14&quot;
temperature=&quot;53&quot; rain-hour=&quot;0&quot; rain-midnight=&quot;0&quot; humidity=&quot;40&quot; pressure=&quot;10090&quot; /&gt;
...
&lt;/aprs&gt;
</code></pre>
<p>The naive approach is to just import these documents verbatim into one large collection and setup a few basic indices:</p>
<ol>
<li>a <code>xs:string</code> index on <code>s:report/@from</code> ,</li>
<li>a <code>xs:dateTime</code> index on <code>s:report/@received</code> ,</li>
<li>a geospatial index on the attribute pair <code>s:report/@longitude</code> and <code>s:report/@latitude.</code></li>
</ol>
<p>My tool of choice for importing these documents is <a href="http://www.w3.org/TR/xproc">XProc</a> . ¬†The pipeline is rather simple:</p>
<pre><code>&lt;p:declare-step xmlns:p=&quot;http://www.w3.org/ns/xproc&quot;
                xmlns:c=&quot;http://www.w3.org/ns/xproc-step&quot;
                xmlns:ml=&quot;http://xmlcalabash.com/ns/extensions/marklogic&quot;
                xmlns:s=&quot;http://weather.milowski.com/V/APRS/&quot;
                version=&quot;1.0&quot;
                name=&quot;insert-weather&quot;&gt;
&lt;p:option name='xdb.user'/&gt;
&lt;p:option name='xdb.password'/&gt;
&lt;p:option name='xdb.host'/&gt;
&lt;p:option name='xdb.port'/&gt;
&lt;p:input port=&quot;source&quot;/&gt;

&lt;p:import href=&quot;http://xmlcalabash.com/extension/steps/library-1.0.xpl&quot;/&gt;

&lt;p:delete match=&quot;/s:aprs/s:report[@type='encoded']&quot;/&gt;

&lt;p:delete match=&quot;/s:aprs/s:report[@error]&quot;/&gt;

&lt;ml:insert-document name=&quot;insert&quot; collections=&quot;http://weather.milowski.com/weather/&quot;&gt;
</code></pre>
<pre><code>   &lt;p:with-option name='user' select='$xdb.user'/&gt;
   &lt;p:with-option name='password' select='$xdb.password'/&gt;
   &lt;p:with-option name='host' select='$xdb.host'/&gt;
   &lt;p:with-option name='port' select='$xdb.port'/&gt;
   &lt;p:with-option name=&quot;uri&quot;¬†
                  select=&quot;concat('http://weather.milowski.com/',/s:report/@source,'-',/s:report/@start,'.xml')&quot;/&gt;
</code></pre>
<pre><code>&lt;/ml:insert-document&gt;

</code></pre>
<pre><code>&lt;/p:declare-step&gt;
</code></pre>
<p>You'll notice that I decided to remove errors and encoded data from the original source. ¬†Errors are reports I couldn't parse according the APRS rules and encoded data are non-standard encodings of weather data. ¬†These turn out to be very small percentages of the actual received data. ¬†That is, almost everyone is producing data correctly by the standardize set of rules.</p>
<p>To apply that pipeline over and over again to the documents, I wrote a little daemon process that uses <a href="http://xmlcalabash.com/">Calabash's</a> API to run the pipeline. ¬†The daemon waits for the files to show up in a particular directory, applies the pipeline to documents it discovers, and then moves them to an archive directory.  That allows me to re-process them in the future if I change my mind--which I did.</p>
<p>A bit of foreshadowing never hurts. ¬†I'll post more on the results of this later. ¬†I've got some queries to write.</p>
</article>
